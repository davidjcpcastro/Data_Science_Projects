{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Final Project \n",
    "\n",
    "Welcome to your Reinforcement Learning project focused on developing an RL agent capable of playing chess at a strategic level. Chess has long been considered a benchmark for measuring AI capabilities, and this project aims to leverage the power of RL to create an intelligent agent that can make optimal decisions in complex chess positions. By combining the principles of reinforcement learning with the rich strategic domain of chess, you will explore new approaches to create the most effective chess player.\n",
    "\n",
    "## Project Objectives:\n",
    "\n",
    "* Train an RL agent to play chess: The primary objective of this project is to develop an RL agent that can play chess at a high level of proficiency. The agent should be capable of evaluating chess positions and making strategic decisions.\n",
    "\n",
    "* Optimize decision-making using RL algorithms: Explore different RL algorithms, as seen in class, to train the agent. Compare and analise their effectiveness in learning and decision-making capabilities in the context of chess.\n",
    "\n",
    "* Use a challenging chess environment: Use a comprehensive environment for the agent to interact with, representing the rules and dynamics of chess. This environment will provide a realistic and challenging setting for the agent's training and evaluation.\n",
    "\n",
    "* Evaluate and benchmark performance: Assess the performance of the RL agent against different benchmarks from existing chess engines. You will compare your agent's performance to established chess engines to measure progress and identify areas for improvement.\n",
    "\n",
    "\n",
    "### Extra Objectives:\n",
    "\n",
    "* Investigate transfer learning and generalization: Explore techniques for transfer learning to leverage knowledge acquired in related domains or from pre-training on large chess datasets. Investigate the agent's ability to generalize its knowledge.\n",
    "\n",
    "* Enhance interpretability and analysis: Develop methods to analise the agent's decision-making process and provide insights into its strategic thinking. Investigate techniques to visualize the agent's evaluation of chess positions and understand its reasoning behind specific moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Play Chess! \n",
    "\n",
    "As you know [Chess](https://en.wikipedia.org/wiki/Chess) is a board game for two players, called White and Black, each controlling an army of chess pieces in their color, with the objective to checkmate the opponent's king.\n",
    "\n",
    "Chess is an abstract strategy game that involves no hidden information and no use of dice or cards. It is played on a chessboard with 64 squares arranged in an eight-by-eight grid. At the start, each player controls sixteen pieces: one king, one queen, two rooks, two bishops, two knights, and eight pawns. White moves first, followed by Black. Checkmating the opponent's king involves putting the king under immediate attack (in \"check\") whereby there is no way for it to escape.\n",
    "\n",
    "\n",
    "![](Images/CHESS_MOVES.PNG)\n",
    "\n",
    "* The king moves one square in any direction. There is also a special move called castling that involves moving the king and a rook. The king is the most valuable piece — attacks on the king must be immediately countered, and if this is impossible, the game is immediately lost.\n",
    "* A rook can move any number of squares along a rank or file, but cannot leap over other pieces. Along with the king, a rook is involved during the king's castling move.\n",
    "* A bishop can move any number of squares diagonally, but cannot leap over other pieces.\n",
    "* A queen combines the power of a rook and bishop and can move any number of squares along a rank, file, or diagonal, but cannot leap over other pieces.\n",
    "* A knight moves to any of the closest squares that are not on the same rank, file, or diagonal. (Thus the move forms an \"L\"-shape: two squares vertically and one square horizontally, or two squares horizontally and one square vertically.) The knight is the only piece that can leap over other pieces.\n",
    "* A pawn can move forward to the unoccupied square immediately in front of it on the same file, or on its first move it can advance two squares along the same file, provided both squares are unoccupied (black dots in the diagram). A pawn can capture an opponent's piece on a square diagonally in front of it by moving to that square (black crosses). It cannot capture a piece while advancing along the same file. A pawn has two special moves: the en passant capture and promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import gym\n",
    "import gym_chess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The agent receives a reward of +1 when the white player makes a winning move, and a reward of -1 when the black player makes a winning move. \n",
    "\n",
    "All other rewards are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluationg your agent with [Stockfish](https://github.com/zhelyabuzhsky/stockfish)\n",
    "\n",
    "In order to have a good enough idea that our agent is actually playing well we need a benchmarkable opponent.\n",
    "\n",
    "As such we need to install stockfish a free and open-source chess engine. Stockfish has consistently ranked first or near the top of most chess-engine rating lists and, as of April 2023, is the strongest CPU chess engine in the world.\n",
    "\n",
    "`pip install stockfish`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockfish import Stockfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockFish has a python api as seen above, nevertheless the engine still needs to be downloaded [here](https://stockfishchess.org/download/) and used in the path.\n",
    "\n",
    "NOTE: You were given an engine already in moodle, nevertheless different computer systems (Windows, Mac, Ubuntu) might require other Stockfish engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# David\n",
    "Stockfish_path = \"C:/Users/David/Desktop/Nova IMS/2º semestre/Reinforcement Learning/project/stockfish_15.1_win_x64_avx2/stockfish-windows-2022-x86-64-avx2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to Play Chess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial state\n",
    "state = chess.Board()\n",
    "\n",
    "# Set the counter for the number of steps\n",
    "counter = 0\n",
    "\n",
    "# Define the Deep Q-Network (DQN) Model\n",
    "input_shape = (8, 8, 12)  # Assuming a chess board representation with channels for each piece type\n",
    "action_space_size = 4096\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(action_space_size, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.agent_plays = []\n",
    "    \n",
    "    def add(self, state, action, reward, next_state):\n",
    "        experience = (state, action, reward, next_state)\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "        if len(self.buffer) > self.max_size:\n",
    "            self.buffer.pop(0)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = np.random.choice(len(self.buffer), size=batch_size, replace=False)\n",
    "        states, actions, rewards, next_states = zip(*[self.buffer[i] for i in batch])\n",
    "        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states)\n",
    "\n",
    "replay_buffer = ReplayBuffer(max_size=100000)\n",
    "\n",
    "def preprocess_state(board):\n",
    "    \"\"\"\n",
    "    Preprocess the chess board state.\n",
    "\n",
    "    Args:\n",
    "        board (chess.Board): The chess board.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The preprocessed state array.\n",
    "    \"\"\"\n",
    "    state_array = np.zeros((8, 8, 12))  # Reshape to match expected input shape\n",
    "    for i in range(64):\n",
    "        piece = board.piece_at(i)\n",
    "        if piece is not None:\n",
    "            piece_type = piece.piece_type\n",
    "            color = int(piece.color)\n",
    "            channel = piece_type - 1 + color * 6\n",
    "            row = i // 8\n",
    "            col = i % 8\n",
    "            state_array[row, col, channel] = 1\n",
    "    return state_array\n",
    "\n",
    "\n",
    "def select_action(board, dqn_model, current_step, total_steps):\n",
    "    # Calculate the updated epsilon value based on the current step and total steps\n",
    "    epsilon = max(0.1, 1.0 - current_step / total_steps)\n",
    "\n",
    "    # Use epsilon-greedy exploration\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(list(board.legal_moves))\n",
    "    else:\n",
    "        if agent_plays:\n",
    "            # Use agent's recorded plays if available\n",
    "            return agent_plays.pop(0)\n",
    "        else:\n",
    "            state_array = preprocess_state(board)\n",
    "            state_input = np.array([state_array])\n",
    "            q_values = dqn_model.predict(state_input)[0]\n",
    "            valid_moves = list(board.legal_moves)\n",
    "            valid_move_indices = [move_to_index(move) for move in valid_moves]\n",
    "            valid_q_values = [q_values[i] for i in valid_move_indices]\n",
    "            return valid_moves[np.argmax(valid_q_values)]\n",
    "\n",
    "\n",
    "def move_to_index(move):\n",
    "    \"\"\"\n",
    "    Convert a chess move to an index.\n",
    "\n",
    "    Args:\n",
    "        move (chess.Move): A chess move.\n",
    "\n",
    "    Returns:\n",
    "        int: The index corresponding to the move.\n",
    "    \"\"\"\n",
    "    return move.from_square * 64 + move.to_square\n",
    "\n",
    "import chess\n",
    "import chess.engine\n",
    "import numpy as np\n",
    "\n",
    "def generate_episode(stockfish_path, dqn_model, replay_buffer, epsilon):\n",
    "    engine = chess.engine.SimpleEngine.popen_uci(stockfish_path)\n",
    "    board = chess.Board()\n",
    "    counter = 0\n",
    "\n",
    "    while not board.is_game_over():\n",
    "        state_array = preprocess_state(board)\n",
    "        state_input = np.array([state_array])\n",
    "\n",
    "        if board.turn == chess.WHITE:\n",
    "            # Agent's turn\n",
    "            if np.random.random() < epsilon:\n",
    "                # Explore: select a random legal move\n",
    "                action = np.random.choice(list(board.legal_moves))\n",
    "            else:\n",
    "                # Exploit: select action with highest Q-value from DQN\n",
    "                q_values = dqn_model.predict(state_input)[0]\n",
    "                valid_moves = list(board.legal_moves)\n",
    "                valid_move_indices = [move_to_index(move) for move in valid_moves]\n",
    "                valid_q_values = [q_values[i] for i in valid_move_indices]\n",
    "                action = valid_moves[np.argmax(valid_q_values)]\n",
    "            \n",
    "            # Save agent's play to replay buffer\n",
    "            replay_buffer.agent_plays.append(action)\n",
    "\n",
    "            # Execute action and observe next state and reward\n",
    "            next_state = board.copy()\n",
    "            next_state.push(action)\n",
    "            reward = 0  # Set the reward based on the game outcome later\n",
    "\n",
    "            # Add experience to replay buffer\n",
    "            replay_buffer.add(state_array, move_to_index(action), reward, preprocess_state(next_state))\n",
    "        else:\n",
    "            # Stockfish's turn\n",
    "            result = engine.play(board, chess.engine.Limit(time=2.0))\n",
    "            action = result.move\n",
    "            next_state = board.copy()\n",
    "            next_state.push(action)\n",
    "            reward = 0  # Set the reward based on the game outcome later\n",
    "\n",
    "            # Add experience to replay buffer\n",
    "            replay_buffer.add(state_array, move_to_index(action), reward, preprocess_state(next_state))\n",
    "\n",
    "        board.push(action)\n",
    "        counter += 1\n",
    "\n",
    "    # Set the reward based on the game outcome\n",
    "    result = None\n",
    "    if board.is_checkmate():\n",
    "        result = 1 if board.turn == chess.BLACK else -1\n",
    "    elif board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves():\n",
    "        result = 0\n",
    "\n",
    "    engine.quit()\n",
    "    return result, counter\n",
    "\n",
    "\n",
    "def deep_q_learning(stockfish_path, dqn_model, replay_buffer, epsilon, batch_size, gamma, num_iterations):\n",
    "    game_results = []  # To store the results of each game\n",
    "    moves_per_game = []  # To store the number of moves in each game\n",
    "\n",
    "    for iteration in range(1, num_iterations + 1):\n",
    "        result, num_moves = generate_episode(stockfish_path, dqn_model, replay_buffer, epsilon)\n",
    "        game_results.append(result)\n",
    "        moves_per_game.append(num_moves)\n",
    "\n",
    "        # Train the DQN model on the replay buffer\n",
    "        states, actions, rewards, next_states = replay_buffer.sample(batch_size)\n",
    "        targets = rewards + gamma * np.amax(dqn_model.predict(next_states), axis=1)\n",
    "        targets_full = dqn_model.predict(states)\n",
    "        ind = np.array([i for i in range(batch_size)])\n",
    "        targets_full[[ind], [actions]] = targets\n",
    "\n",
    "        dqn_model.fit(states, targets_full, epochs=1, verbose=0)\n",
    "        \n",
    "        # Update agent's plays for next iteration\n",
    "        agent_plays = replay_buffer.agent_plays.copy()\n",
    "        replay_buffer.agent_plays.clear()\n",
    "\n",
    "        # Print the progress\n",
    "        print(f\"Iteration: {iteration}/{num_iterations} | Result: {result} | Moves: {num_moves}\")\n",
    "\n",
    "    # Plot the game results\n",
    "    plt.plot(game_results)\n",
    "    plt.xlabel('Game')\n",
    "    plt.ylabel('Result')\n",
    "    plt.title('Game Results')\n",
    "    plt.show()\n",
    "\n",
    "    # Create a dataframe with game results and moves per game\n",
    "    df = pd.DataFrame({'Result': game_results, 'Moves': moves_per_game})\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Iteration: 1/2 | Result: -1 | Moves: 26\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Iteration: 2/2 | Result: -1 | Moves: 30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>Moves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result  Moves\n",
       "0      -1     26\n",
       "1      -1     30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Deep Q-Learning\n",
    "deep_q_learning(Stockfish_path, model, replay_buffer, epsilon=0.1, batch_size=4, gamma=0.9, num_iterations=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning algorithm for playing chess. \n",
    "\n",
    "- The **ReplayBuffer** class is defined, which is used to store and sample experiences for training the Deep Q-Network (DQN) model. The replay buffer has a maximum size defined by the max_size parameter, and new experiences are added using the add method. If the buffer exceeds the maximum size, the oldest experience is removed. Experiences can be sampled using the sample method, which randomly selects a batch of experiences from the buffer.\n",
    "\n",
    "- The **preprocess_state** function takes a chess board object and converts it into a preprocessed state array. The state array has a shape of (8, 8, 12) to represent the chess board, where each square can have up to 12 channels (6 piece types for each color). The function iterates over each square on the board, retrieves the piece type and color, and assigns a value of 1 to the corresponding channel in the state array.\n",
    "\n",
    "- The **select_action** function is responsible for selecting an action (move) to play. The exploration_rate starts at epsilon and gradually decreases as the number of steps (counter) increases. This way, the agent starts with a high exploration rate, favoring exploratory actions, and the rate decreases over time, favoring more exploitative actions. The function preprocesses the current board state using the preprocess_state function and then feeds it to the DQN model to get the Q-values for each possible action. The valid moves and their corresponding Q-values are extracted, and either a random move or the move with the highest Q-value is returned.\n",
    "\n",
    "- The **move_to_index** function converts a chess move object into an index. It uses the from_square and to_square attributes of the move to calculate the corresponding index.\n",
    "\n",
    "- The **generate_episode** function plays a single episode of chess using the DQN model and a chess engine (Stockfish) to generate moves for the opponent. The function takes the path to the Stockfish engine, the DQN model, the replay buffer, and the exploration rate (epsilon) as input. It initializes the chess board and starts a loop until the game is over. In each iteration, it preprocesses the current board state, selects an action using the select_action function, applies the action to the board, and adds the experience to the replay buffer. If it's the opponent's turn, it uses the Stockfish engine to generate the move. After each move, the function checks if the game is over and assigns a reward based on the game outcome. Finally, it returns the result of the game (1 for win, 0 for draw, -1 for loss) and the number of moves played.\n",
    "\n",
    "- The **deep_q_learning** function is the main training loop for the DQN model. It takes the Stockfish engine path, the DQN model, the replay buffer, the exploration rate (epsilon), batch size, discount factor (gamma), and the number of training iterations as input. It initializes two lists, game_results and moves_per_game, to store the results and number of moves for each game played. It then iterates for the specified number of iterations and calls the generate_episode function to play a game and obtain the result and number of moves. The result and number of moves are stored in the respective lists. After each game, the DQN model is trained using experiences sampled from the replay buffer. The Q-values of the next states are calculated and used to update the Q-values of the current states and selected actions. The training progress is printed, and the game results are plotted at the end. Finally, a dataframe containing the game results and moves per game is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
